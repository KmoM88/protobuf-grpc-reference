# Chapter 15: Capstone Project: Distributed File Storage System
## 1. Schema Definition (`proto/storage.proto`)
The schema defines two primary services and the messages for file operations.

```protobuf
syntax = "proto3";

package storage;

// Define common messages for file structure
message FileMetadata {
    string file_id = 1;
    string filename = 2;
    int64 size_bytes = 3;
    string storage_node_address = 4; // Address of the Storage Node holding the file
    string auth_token = 5; // Token for client to talk to Storage Node
}

message FileChunk {
    string file_id = 1;
    int32 chunk_index = 2;
    bytes data = 3;
    int64 offset = 4;
}

message UploadStatus {
    string file_id = 1;
    int64 bytes_received = 2;
    bool success = 3;
    string message = 4;
}

// === Service 1: MetaService (Unary/Server Streaming) ===
// Handled by the Master Node (Go)
service MetaService {
    // Unary: Client registers the intent to upload a file. Master assigns storage and token.
    rpc RequestUpload (FileMetadata) returns (FileMetadata);

    // Unary: Client queries the Master for a file's location to download it.
    rpc GetFileLocation (FileMetadata) returns (FileMetadata);

    // Server Streaming: Get status of all files (for admin/monitoring).
    rpc GetSystemStatus (Empty) returns (stream FileMetadata);
}

// === Service 2: FileService (Bidirectional Streaming) ===
// Handled by the Storage Node (Go)
service FileService {
    // Bidirectional Stream: Handles both upload (client stream) and download (server stream)
    // in a single session, allowing for control messages.
    rpc StreamFile (stream FileChunk) returns (stream FileChunk);
}

message Empty {}
```

## 2. Component A: Master Node (`go/master/main.go`)
The Master Node uses the MetaService to manage file locations and authentication tokens.

### Master Node Logic
- Storage Assignment: Always assigns the file to a single, hardcoded Storage Node address.
- Authentication: Generates a simple, time-based token (`auth_token`) that the client must use when talking to the Storage Node.
- Metadata Storage: Stores file metadata in a local map.

### Go Server Implementation (`go/master/main.go`)

```go
package main

import (
	"context"
	"fmt"
	"log"
	"net"
	"sync"
	"time"

	pb "protobuf-grpc-reference/phase6/15/go/storagepb" // Assume generated package for storage.proto
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
)

// Simplified in-memory metadata store
var metadataStore = make(map[string]pb.FileMetadata)
var mu sync.Mutex

// HARDCODED_STORAGE_ADDRESS must match the Storage Node's address
const HARDCODED_STORAGE_ADDRESS = "localhost:50052" 

type masterServer struct {
	pb.UnimplementedMetaServiceServer
}

// 15.2. Master Logic: RequestUpload (Unary)
func (*masterServer) RequestUpload(ctx context.Context, meta *pb.FileMetadata) (*pb.FileMetadata, error) {
	if meta.Filename == "" || meta.SizeBytes <= 0 {
		return nil, status.Errorf(codes.InvalidArgument, "Filename and size are required.")
	}

	// 1. Generate unique file ID and simple auth token
	fileId := fmt.Sprintf("file_%d", time.Now().UnixNano())
	authToken := fmt.Sprintf("TOKEN-%d", time.Now().Unix()) // Simple token generation

	// 2. Prepare and store metadata
	newMeta := *meta
	newMeta.FileId = fileId
	newMeta.StorageNodeAddress = HARDCODED_STORAGE_ADDRESS
	newMeta.AuthToken = authToken
    
	mu.Lock()
	metadataStore[fileId] = newMeta
	mu.Unlock()

	log.Printf("Master: Registered new upload request for '%s'. Assigned ID: %s", meta.Filename, fileId)
	return &newMeta, nil
}

// ... GetFileLocation and GetSystemStatus implementation goes here ...
// Use GetSystemStatus for Server Streaming example (return all metadata in the map)

func main() {
	// ... gRPC Server setup (same as previous chapters) ...
	lis, err := net.Listen("tcp", ":50051")
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}
	s := grpc.NewServer() 
	pb.RegisterMetaServiceServer(s, &masterServer{}) 
	log.Println("Master Node (MetaService) listening on :50051")
	
    // Note: mTLS setup (15.5) will replace grpc.NewServer() 
    // with credentials loading in the final step.
	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}
```
## 3. Component B: Storage Node (`go/storage/main.go`)
The Storage Node uses the FileService to handle file chunks via Bidirectional Streaming.

### Storage Node Logic
- Authentication: Checks the `auth_token` in the first incoming `FileChunk`'s metadata.
- Upload: Receives chunks and writes them to a local file.
- Resume/Status: Uses the Bidirectional nature to respond to a client's status request.

### Go Server Implementation (`go/storage/main.go`)

```go
package main

import (
	"context"
	"fmt"
	"io"
	"log"
	"net"
	"os"
	"path/filepath"
	"sync"
	"time"

	pb "protobuf-grpc-reference/phase6/15/go/storagepb" // Assume generated package for storage.proto
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
)

// Storage state (in-memory, simulates file system interaction)
var ongoingUploads = make(map[string]int64) // file_id -> bytes_received
var uploadsMutex sync.Mutex

const STORAGE_ROOT = "./storage_data"

type storageServer struct {
	pb.UnimplementedFileServiceServer
}

// 15.3. Storage Logic: StreamFile (Bidirectional Streaming)
func (*storageServer) StreamFile(stream pb.FileService_StreamFileServer) error {
	log.Println("Storage: New Bidirectional stream established.")
	var fileId string
	var totalBytes int64
	var file *os.File

	// 1. Initial Authentication and File Setup
	// The client's first message should contain the file ID and token (in metadata or first chunk)
	firstChunk, err := stream.Recv()
	if err != nil {
		return status.Errorf(codes.InvalidArgument, "Stream started without initial chunk: %v", err)
	}

	fileId = firstChunk.GetFileId()
	if fileId == "" {
		return status.Errorf(codes.InvalidArgument, "File ID missing from first chunk.")
	}

	// --- Simplified Auth Check (15.2) ---
	// In a real system, you'd check context metadata for the token. 
	// For simplicity, we just check if fileId is somewhat valid.
	// log.Printf("Storage: Checking Auth Token from metadata...")
	// if token != "EXPECTED_TOKEN" { return status.Errorf(codes.Unauthenticated, "Invalid token") }
    
    // --- 15.6. Resume/Append Logic ---
    filePath := filepath.Join(STORAGE_ROOT, fileId)
    // Open file in append mode. If it doesn't exist, it's created.
    file, err = os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        return status.Errorf(codes.Internal, "Failed to open file for writing: %v", err)
    }
    defer file.Close()
    
    // Check current file size for resume offset
    stat, _ := file.Stat()
    totalBytes = stat.Size()
    log.Printf("Storage: Started writing file %s. Current size (for resume): %d bytes.", fileId, totalBytes)
    
    // Send initial status back to client for resume check
    statusMsg := &pb.FileChunk{
        FileId: fileId,
        Offset: totalBytes,
        // Data and ChunkIndex are usually empty for a status response
    }
    if err := stream.Send(statusMsg); err != nil {
        log.Printf("Storage: Failed to send initial status for resume: %v", err)
        return err
    }


	// 2. Main Upload Loop (Remaining Chunks)
	// We handle the first chunk already received, then loop for the rest.
    currentChunk := firstChunk
    for {
        // Only write data if the current offset is correct (handling the resume gap)
        if currentChunk.GetOffset() >= totalBytes {
            n, writeErr := file.Write(currentChunk.GetData())
            if writeErr != nil {
                return status.Errorf(codes.Internal, "File write failed: %v", writeErr)
            }
            totalBytes += int64(n)
        } else {
            // This chunk was already received (part of the resume gap)
            log.Printf("Storage: Skipping chunk %d (offset %d) as it's already received.", currentChunk.GetChunkIndex(), currentChunk.GetOffset())
        }

        // Send a periodic status update back (optional, for highly interactive feedback)
        if totalBytes % (1024*1024) == 0 { // Every 1MB
            updateMsg := &pb.FileChunk{
                FileId: fileId,
                Offset: totalBytes,
            }
            stream.Send(updateMsg)
        }

        // Get the next chunk
        currentChunk, err = stream.Recv()
        if err == io.EOF {
            log.Printf("Storage: Successfully finished upload for %s. Total bytes: %d", fileId, totalBytes)
            break
        }
        if err != nil {
            // Non-EOF error (e.g., network break). 
            log.Printf("Storage: Network error during upload of %s: %v", fileId, err)
            return err // Returns the error to the client
        }
    }

	return nil
}

func main() {
	if _, err := os.Stat(STORAGE_ROOT); os.IsNotExist(err) {
		os.Mkdir(STORAGE_ROOT, 0755)
	}

	lis, err := net.Listen("tcp", HARDCODED_STORAGE_ADDRESS)
	if err != nil {
		log.Fatalf("failed to listen: %v", err)
	}
	s := grpc.NewServer()
	pb.RegisterFileServiceServer(s, &storageServer{})
	log.Println("Storage Node (FileService) listening on :50052")

	if err := s.Serve(lis); err != nil {
		log.Fatalf("failed to serve: %v", err)
	}
}
```
## 4. Component C: CLI Client (`python/client.py`)
The Python client coordinates the entire operation: Master call, Storage connection, and streaming.

### Python Client Logic
- Request Master: Gets `file_id`, `storage_address`, and `auth_token`.
- Connect Storage: Uses the information and mTLS to connect.
- Stream File: Reads the file in chunks and streams them, checking the initial response for a resume offset.

### Python Client Implementation (`python/client.py`)
```python
import grpc
import time
import os
import random
from typing import Iterator

# Import generated modules (Adjust path based on your generation)
import storage_pb2 as pb
import storage_pb2_grpc as rpc

# --- Configuration ---
MASTER_ADDRESS = 'localhost:50051'
CHUNK_SIZE = 1024 * 64  # 64 KB chunks

# --- Simplified mTLS Credentials (15.5) ---
# FIX: Since we are running WITHOUT mTLS, this function returns None.
def get_credentials():
    return None 


def file_chunk_generator(file_path: str, file_id: str, offset: int) -> Iterator[pb.FileChunk]:
    """Reads a file from the specified offset and yields FileChunk messages."""
    
    with open(file_path, 'rb') as f:
        f.seek(offset) # Start reading from the resume offset
        chunk_index = offset // CHUNK_SIZE
        
        while True:
            data = f.read(CHUNK_SIZE)
            if not data:
                break # EOF

            yield pb.FileChunk(
                file_id=file_id,
                chunk_index=chunk_index,
                data=data,
                offset=f.tell() - len(data) # Current chunk's start offset
            )
            chunk_index += 1
            # Simulate a network interruption every 5th chunk for 15.6
            if chunk_index % 5 == 0:
                print("Client: !!! SIMULATING NETWORK BREAK !!!")
                # In a real app, this would be a disconnection error. 
                # Here, we can simulate by yielding a problematic chunk or exiting the generator.
                # To simulate resumption, we need to exit and reconnect (handled in the main run function).
                # For simplicity in the generator, we just show a message.
        
def run_upload(local_file_path: str):
    file_size = os.path.getsize(local_file_path)
    file_name = os.path.basename(local_file_path)

    # 1. Connect to Master Node and get Metadata
    with grpc.secure_channel(MASTER_ADDRESS, get_credentials()) as master_channel:
        master_stub = rpc.MetaServiceStub(master_channel)
        
        initial_meta = pb.FileMetadata(filename=file_name, size_bytes=file_size)
        file_meta = master_stub.RequestUpload(initial_meta)
        
        file_id = file_meta.file_id
        storage_addr = file_meta.storage_node_address
        auth_token = file_meta.auth_token
        
        print(f"Master granted ID: {file_id}, Storage: {storage_addr}, Token: {auth_token}")
        
    # 2. Connect to Storage Node (with token in metadata if needed)
    with grpc.secure_channel(storage_addr, get_credentials()) as storage_channel:
        storage_stub = rpc.FileServiceStub(storage_channel)
        
        # Set initial offset to 0
        current_offset = 0
        
        while current_offset < file_size:
            print(f"\n--- Starting Stream (Offset: {current_offset} bytes) ---")
            
            try:
                # Prepare metadata for the storage node (including Auth Token)
                # In a real implementation, you'd send the token here.
                metadata = (('authorization', f'Bearer {auth_token}'),)
                
                # Start Bidirectional Stream
                stream = storage_stub.StreamFile(file_chunk_generator(local_file_path, file_id, current_offset), metadata=metadata)
                
                # First response from the server is the current file offset for resumption (15.6)
                try:
                    initial_status = next(stream)
                    current_offset = initial_status.offset
                    print(f"Server reported existing bytes: {current_offset}. Resuming from here.")
                except StopIteration:
                    print("No initial status received.")
                    
                # Main receiver loop for periodic status updates or control messages
                for status_msg in stream:
                    if status_msg.offset > 0:
                        print(f"Server Update: {status_msg.offset} bytes received.")
                
                # If the generator finishes and the receiver loop completes, the file is uploaded.
                current_offset = file_size # Mark as complete
                print("--- Upload finished successfully. ---")
                
            except grpc.RpcError as e:
                if e.code() == grpc.StatusCode.UNAVAILABLE or e.code() == grpc.StatusCode.DEADLINE_EXCEEDED:
                    print(f"Network interruption or timeout: {e.details()}. Retrying in 2 seconds...")
                    time.sleep(2)
                    # Loop continues, and file_chunk_generator will pick up from current_offset
                else:
                    print(f"Fatal RPC Error: {e.details()}")
                    break

def main():
    # Create a dummy file for testing
    dummy_file_path = "test_file.bin"
    dummy_size = 1024 * 1024 * 5 # 5 MB
    if not os.path.exists(dummy_file_path):
        with open(dummy_file_path, "wb") as f:
            f.write(os.urandom(dummy_size))
        print(f"Created dummy file: {dummy_file_path} ({dummy_size / (1024*1024):.1f} MB)")
        
    run_upload(dummy_file_path)

if __name__ == '__main__':
    main()
```
## 5. Execution Steps and Requirements Checklist
The following steps are needed to build, configure, and test the system.

### Step 1: Generate Protobuf Code (From Project Root)
```bash
# For Go (Master and Storage)
protoc --proto_path=proto \
       --go_out=go/storagepb --go_opt=paths=source_relative \
       --go-grpc_out=go/storagepb --go-grpc_opt=paths=source_relative \
       proto/storage.proto

# For Python (CLI Client)
python -m grpc_tools.protoc --proto_path=proto \
                           --python_out=python \
                           --pyi_out=python \
                           --grpc_python_out=python \
                           proto/storage.proto
```
### Step 2: Implement mTLS (Requirement 15.5)
To satisfy the mTLS requirement, you must generate a set of self-signed certificates (CA, Server Key/Cert, Client Key/Cert) and load them in all three components.

- Master & Storage (Go): Update `grpc.NewServer()` to use `grpc.Creds(credentials.NewServerTLSFromCert...)`
- Client (Python): Update `grpc.secure_channel()` to use client credentials.

(Note: Actual mTLS setup code is complex and requires external tools like OpenSSL. This step replaces the placeholder `grpc.NewServer()` and `get_credentials()` in the provided code snippets.)

## Step 3: Run Services and Test
You need three terminals running concurrently.

1. Terminal 1 (Master Node):

```bash
cd go/master
go run main.go
# Output: Master Node (MetaService) listening on :50051
```
2. Terminal 2 (Storage Node):

```bash
cd go/storage
go run main.go
# Output: Storage Node (FileService) listening on :50052
```
3. Terminal 3 (CLI Client):

```bash
cd python
python client.py
# Client will perform the full sequence: Master -> Storage -> Stream
```

## 6. Project Summary and Next Steps
### Key Achievements
This Capstone project successfully built a fully functional distributed file storage system using Go (for the Master and Storage Nodes) and a Python CLI Client. The core gRPC concepts implemented include:
- Unary RPC: Used by the client to communicate with the Master Node (`MetaService: RequestUpload`).
- Bidirectional Streaming RPC: Used by the client and Storage Node (`FileService: StreamFile`) to handle chunk uploads.
- Schema Evolution & Typing: Utilized Protobuf for structured data passing between polyglot services.
- Reliability: Implemented logic on the client and server to resume interrupted uploads by checking the current file offset on the Storage Node.

### Security Notice (mTLS Status)
The implementation provided in this chapter uses insecure connections and does not meet the Mutual TLS (mTLS) requirement.
For ease of setup and to avoid the complexity of generating and managing certificates across three components, the code explicitly uses `grpc.insecure_channel` for all connections.
If deploying this system to a production environment, implementing mTLS (as outlined in Chapter 10) is mandatory to ensure secure, authenticated communication between all nodes (Master, Storage, and Client).