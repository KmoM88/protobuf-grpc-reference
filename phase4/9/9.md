# Chapter 9: Reliability & Error Handling
Reliability in gRPC hinges on two core concepts: using standardized Status Codes to communicate failure and implementing robust Deadlines and Retries to ensure service stability.
## 9.1. The gRPC Status Codes
gRPC uses a fixed set of standardized status codes (defined in `google.rpc.Code`) to communicate the result of an RPC call. These codes provide a structured and machine-readable reason for failure, allowing clients to make informed decisions (e.g., whether to retry).

| Code | Description | Client Action |
|------|-------------|---------------|
| OK (0) | The RPC succeeded. | Proceed with result. |
| CANCELLED (1) | The operation was cancelled (usually by the client). | Do not retry. |
| UNKNOWN (2) | Unknown error or non-gRPC error. | Usually safe to retry later. |
| INVALID_ARGUMENT (3) | Client specified an invalid argument. | Do not retry. Fix client input. |
| DEADLINE_EXCEEDED (4) | The deadline expired before the operation could complete. | Safe to retry (maybe with a longer deadline). |
| NOT_FOUND (5) | Some requested entity was not found. | Do not retry. |
| ALREADY_EXISTS (6) | The entity you tried to create already exists. | Do not retry. |
| PERMISSION_DENIED (7) | The caller does not have permission. | Do not retry. |
| UNAUTHENTICATED (16) | The request does not have valid credentials. | Do not retry. Fix credentials. |
| RESOURCE_EXHAUSTED (8) | Some resource has been exhausted (e.g., rate limits). | Retry with backoff. |
| UNIMPLEMENTED (12) | The RPC is not implemented by the server. | Do not retry. Fix client logic or server deployment. |
| UNAVAILABLE (14) | The service is currently unavailable (e.g., server crash, overload). | Safe to retry with backoff. |

## 9.2. Go: Using the `status` and `codes` packages.
In Go, gRPC errors are created and handled using the `google.golang.org/grpc/status` and `google.golang.org/grpc/codes` packages.

### Server (Returning Errors)
The server must explicitly create and return a `status.Status` object.

```go
// Server implementation
func (s *server) MyRPC(ctx context.Context, req *pb.Request) (*pb.Response, error) {
    if req.GetId() == 0 {
        // Return a structured error with the code and message
        return nil, status.Errorf(codes.InvalidArgument, "ID cannot be zero")
    }
    // ... success logic ...
    return &pb.Response{}, nil
}
```
### Client (Handling Errors)
The client uses `status.FromError` to extract the code and details from the returned error.
```go
// Client implementation
response, err := client.MyRPC(ctx, request)
if err != nil {
    st, ok := status.FromError(err)
    if ok {
        // Handle gRPC specific status codes
        if st.Code() == codes.InvalidArgument {
            log.Printf("Input error: %s", st.Message())
        } else if st.Code() == codes.Unavailable {
            log.Println("Server unavailable, retrying later.")
        }
    } else {
        // Handle non-gRPC errors (e.g., network timeout before connection)
        log.Printf("Non-gRPC error: %v", err)
    }
}
```
## 9.3. C++: Catching exceptions vs checking Status.
Unlike some C++ paradigms that rely heavily on exceptions, gRPC's C++ interface typically returns a `grpc::Status` object.

```c++
// Client Call in C++
grpc::ClientContext context;
MyResponse response;

// The call returns a Status object, not the response directly
grpc::Status status = stub_->MyRPC(&context, request, &response);

if (status.ok()) {
    // Success logic
} else {
    // Check the error code
    std::cout << "RPC failed: " << status.error_code() 
              << ", " << status.error_message() << std::endl;
}
```
Key Point: You check `status.ok()` or `status.error_code()` directly; you do not usually catch gRPC exceptions for standard error handling.

## 9.4. Deadlines & Timeouts.
Deadlines are a mechanism where the client specifies the maximum amount of time it is willing to wait for an RPC to complete.
- Why they are necessary: Deadlines prevent clients from blocking indefinitely waiting for a slow or failed server. If a service A times out waiting for service B, it should fail gracefully rather than holding resources until B is eventually fixed (preventing cascading failures).

### Setting deadlines in Go Contexts.
In Go, deadlines are enforced by attaching a `context.Context` with a timeout or a specific time to the RPC call.

```go
// Client: Set a 5-second timeout
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel() // Always release resources

// If the RPC takes longer than 5s, it returns codes.DEADLINE_EXCEEDED
response, err := client.MyRPC(ctx, request)
```
### Setting deadlines in C++ `ClientContext`.
In C++, you set the absolute deadline time directly on the `ClientContext`.

```c++
// Client: Set a deadline 5 seconds from now
std::chrono::system_clock::time_point deadline = 
    std::chrono::system_clock::now() + std::chrono::seconds(5);

grpc::ClientContext context;
context.set_deadline(deadline); 

// ... RPC call ...
```
## 9.5. Retries: Configuring exponential backoff policies.
Retries are attempts by the client to re-execute an RPC after it fails with a transient error (e.g., `UNAVAILABLE`, `RESOURCE_EXHAUSTED`, `DEADLINE_EXCEEDED`).
- Transient Failures (Safe to Retry): `UNAVAILABLE`, `DEADLINE_EXCEEDED`, `RESOURCE_EXHAUSTED`, `INTERNAL` (sometimes), `UNKNOWN` (sometimes).
- Non-Transient Failures (Do Not Retry): `INVALID_ARGUMENT`, `NOT_FOUND`, `PERMISSION_DENIED`, `UNAUTHENTICATED`.

### Exponential Backoff
The most effective strategy for retries is Exponential Backoff. Instead of retrying immediately, the client waits for an exponentially increasing period before the next retry (e.g., 1s, 2s, 4s, 8s, 16s...). This prevents swamping an already overwhelmed server with repeated requests.
- Jitter: To prevent synchronization across multiple clients all retrying at the exact same moment, a small, random delay (jitter) is added to the backoff period.

While retries can be implemented manually by the client, gRPC frameworks often provide automatic retry mechanisms configurable via Method Configuration in the channel setup.